{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bornord/DeepLearning/blob/main/Projet_LeVrai2.0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lg48JBWoBk3B"
      },
      "source": [
        "PROJET CLASSIFICATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EK5VpgDHBrba"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/Bornord/DeepLearning.git\n",
        "#path = \"./iam/tp3/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Flatten\n",
        "\n",
        "from tensorflow.keras.layers import summary\n",
        "from tensorflow.keras.layers import compile\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "model = Sequential()\n",
        "# A COMPLETER\n",
        "model.add(Conv2D(32, kernel_size= (3,3), strides=(1,1), activation = 'relu', input_shape=(64, 64, 3)))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "\n",
        "model.add(Conv2D(64, kernel_size= (3,3), strides=(1,1), activation = 'relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "\n",
        "model.add(Conv2D(96, kernel_size= (3,3), strides=(1,1), activation = 'relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "\n",
        "model.add(Conv2D(128, kernel_size= (3,3), strides=(1,1), activation = 'relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "\n",
        "# ...\n",
        "model.add(Flatten())    # \"Mise à plat\" (vectorisation) du tenseur pour permettre de la connecter à une couche dense  \n",
        "model.add(Dense(512, activation = 'relu'))   # Couche dense, à 512 neurones\n",
        "model.add(Dense(5, activation = 'sigmoid'))   # Couche de sortie\n",
        "\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# AJOUTER EGALEMENT LA FONCTION DE COUT\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizers.Adam(learning_rate=3e-4),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# TODO\n",
        "history = model.fit(X_TRAIN, Y_TRAIN, \n",
        "                    validation_data=(x_val, y_val),\n",
        "                    epochs=100,\n",
        "                    )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt \n",
        "\n",
        "def plot_training_analysis(history):\n",
        "  acc = history.history['accuacy']\n",
        "  val_acc = history.history['val_accuracy']\n",
        "  loss = history.history['binary_crossentropy']\n",
        "  val_loss = history.history['val_loss']\n",
        "\n",
        "  epochs = range(len(loss))\n",
        "\n",
        "  plt.plot(epochs, acc, 'b', linestyle=\"--\",label='Training MAE')\n",
        "  plt.plot(epochs, val_acc, 'g', label='Validation MAE')\n",
        "  plt.title('Training and validation MAE')\n",
        "  plt.legend()\n",
        "\n",
        "  plt.figure()\n",
        "\n",
        "  plt.plot(epochs, loss, 'b', linestyle=\"--\",label='Training loss')\n",
        "  plt.plot(epochs, val_loss,'g', label='Validation loss')\n",
        "  plt.title('Training and validation loss')\n",
        "  plt.legend()\n",
        "\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Transfert d'apprentissage\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import VGG16\n",
        "\n",
        "# TODO \n",
        "conv_base = VGG16(weights='imagenet', # On utilise les poids du réseau déjà pré-entrainé sur la base de données ImageNet\n",
        "                  include_top=False, # On ne conserve pas la partie Dense du réseau originel\n",
        "                  input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_features = conv_base.predict(x_train)\n",
        "train_features = np.reshape(train_features,(train_features.shape[0],2*2*512))\n",
        "\n",
        "val_features = conv_base.predict(x_val)\n",
        "val_features = np.reshape(val_features,(val_features.shape[0],2*2*512))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO \n",
        "model = Sequential()\n",
        " \n",
        "model.add(Dense(256, activation = 'relu', input_shape=(64, 64, 3)))   # Couche dense\n",
        "model.add(Dense(1, activation = 'sigmoid'))   # Couche de sortie\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# AJOUTER EGALEMENT LA FONCTION DE COUT\n",
        "model.compile(optimizer=optimizers.Adam(lr=3e-4),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# COMPLETER AVEC LES TENSEURS SUR LESQUELS EFFECTUER L'APPRENTISSAGE\n",
        "history = model.fit(train_features,\n",
        "                    epochs=50,\n",
        "                    batch_size=16,\n",
        "                    validation_data=val_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizers.Adam(learning_rate=3e-4),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_datagen.flow(x_train, y_train, batch_size=10), \n",
        "                    validation_data=(x_val, y_val),\n",
        "                    epochs=10,\n",
        "                    )"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyN1By+Pkh90ejLO+t7PikYu",
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "Untitled1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
